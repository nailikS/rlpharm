{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import utils\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "xmlfile = r\"C:\\Users\\kilia\\MASTER\\V2Z1551.pml\"\n",
    "\n",
    "tree = ET.parse(xmlfile)\n",
    "root = tree.getroot()\n",
    "FEATURES = [\"H\", \"HBA\", \"HBD\", \"exclusion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_tol(tree, id, newval, target=None):\n",
    "    elm = tree.find(\".//*[@featureId='\"+str(id)+\"']\")\n",
    "    if (elm.get(\"name\") == \"H\") or (elm.get(\"type\") == \"exclusion\"):\n",
    "        elm.find(\"./position\").set('tolerance', newval)\n",
    "        return tree\n",
    "    if target == \"target\":\n",
    "        child = elm.find(\"./target\")\n",
    "        child.set('tolerance', newval)\n",
    "        return tree\n",
    "    if target == \"origin\":\n",
    "        child = elm.find(\"./origin\")\n",
    "        child.set('origin', newval)\n",
    "        return tree\n",
    "    return False\n",
    "\n",
    "def set_weight(id, newval):\n",
    "    elm = tree.find(\".//*[@featureId='\"+str(id)+\"']\")\n",
    "    elm.set(\"weight\", newval)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_tol(tree=tree, id=\"837634895065800895\", newval=\"10\").write(r\"C:\\Users\\kilia\\MASTER\\V2Z1551_modified.pml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4, 4, 4, 4, 4], [4, 4, 4, 4], [4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4]], [[4, 4, 4], [4, 4, 4], [4, 4, 4]]]\n"
     ]
    }
   ],
   "source": [
    "n_feats = np.array([[5,4,3,8], [3,3,3]], dtype=object)\n",
    "nvec = []\n",
    "# codec -> 0: H\n",
    "#          1: HBA\n",
    "#          2: HBD\n",
    "#          3: EXCLUSION\n",
    "#len(n_feats)\n",
    "for i in range(len(n_feats)):\n",
    "    nvec.append([])\n",
    "    for j in range(len(n_feats[i])):\n",
    "        nvec[i].append([])\n",
    "        for k in range(n_feats[i][j]):\n",
    "            nvec[i][j].append(4)\n",
    "print(nvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 2, 4],\n",
       "       [1, 1, 2, 2]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feats = np.array([[5,4,3,8], [3,3,3,3]], dtype=object)\n",
    "\n",
    "# codec -> 0: H\n",
    "#          1: HBA\n",
    "#          2: HBD\n",
    "#          3: EXCLUSION\n",
    "\n",
    "\n",
    "action_space = spaces.MultiDiscrete(n_feats)\n",
    "\n",
    "observation_space = spaces.MultiDiscrete(n_feats)\n",
    "observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['83763489212130077', '837634895065800895'], ['837634894702000876', '837634894751500878', '837634894566000874'], ['837634894919400880'], ['837634894923500881', '837634892436200172', '8376348953118001029', '837634894708900877', '837634894581900875', '837634894754900879', '837634892449700179', '83763489201030076', '837634895061000894', '837634892440900173']]\n"
     ]
    }
   ],
   "source": [
    "featureIds = []\n",
    "root = tree.getroot()\n",
    "for i in range(len(FEATURES)):\n",
    "    featureIds.append([])\n",
    "    if FEATURES[i] != \"exclusion\":\n",
    "        for elm in tree.findall(\".//*[@name='\"+FEATURES[i]+\"']\"):\n",
    "            featureIds[i].append(elm.get(\"featureId\"))\n",
    "    else:\n",
    "        for elm in tree.findall(\".//*[@type='\"+FEATURES[i]+\"']\"):\n",
    "            featureIds[i].append(elm.get(\"featureId\"))\n",
    "print(featureIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureIds = []\n",
    "# for i in range(len(FEATURES)):\n",
    "#     featureIds.append([])\n",
    "#     if FEATURES[i] != \"exclusion\":    \n",
    "#         for elm in tree.findall(\".//*[@name='\"+FEATURES[i]+\"']\"):\n",
    "#             featureIds[i].append(elm.get(\"featureId\"))\n",
    "#     else:\n",
    "#         for elm in tree.findall(\".//*[@type='\"+FEATURES[i]+\"']\"):\n",
    "#             featureIds[i].append(elm.get(\"featureId\"))\n",
    "def get_tol_and_weight(tree, id):\n",
    "    \"\"\"\n",
    "    Get tolerance and weight of a feature\n",
    "    :param tree: tree of Phar file\n",
    "    :param id: featureId\n",
    "    :return: tolerance and weight as separate values, when dealing with HBA and HBD, tolerance of target and origin as well as weight are returned\n",
    "    \"\"\"\n",
    "    \n",
    "    elm = tree.find(\".//*[@featureId='\"+id+\"']\")\n",
    "    if (elm.get(\"name\") == \"H\") or (elm.get(\"type\") == \"exclusion\"):\n",
    "        child = elm.find(\"./position\")\n",
    "        return child.get(\"tolerance\"), elm.get(\"weight\")\n",
    "    else:\n",
    "        child_target = elm.find(\"./target\")\n",
    "        child_origin = elm.find(\"./origin\")\n",
    "        return child_target.get('tolerance'), child_origin.get('tolerance'), elm.get('weight')\n",
    "\n",
    "\n",
    "\n",
    "nvec = []\n",
    "for feature in featureIds:\n",
    "    nvec.append(len(feature))\n",
    "    \n",
    "# currently for one pharmacophore at a time\n",
    "observation_space = []\n",
    "for i in range(len(featureIds)):\n",
    "    observation_space.append([])\n",
    "    for id in featureIds[i]:\n",
    "        observation_space[i].extend(get_tol_and_weight(tree, id))\n",
    "        # for k in range(nfeats[i][j]):\n",
    "        #     nvec[i][j].append()\n",
    "\n",
    "ovec = []\n",
    "for feature in observation_space:\n",
    "    ovec.append(len(feature))\n",
    "\n",
    "# action_space = spaces.MultiDiscrete(nvec*4)\n",
    "# observation_space = spaces.MultiDiscrete(observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiDiscrete([ 8 12  4 40])\n"
     ]
    }
   ],
   "source": [
    "action_space = spaces.MultiDiscrete(np.array(nvec)*4)\n",
    "print(action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1.5', '1.0', '1.5', '1.0'], ['1.5', '1.9499999', '1.0', '1.5', '1.9499999', '1.0', '1.5', '1.9499999', '1.0'], ['1.9499999', '1.5', '1.0'], ['1.0', '1.0', '1.5', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.5', '1.0', '1.5', '1.0', '1.5', '1.0', '1.5', '1.0']]\n",
      "Discrete(36)\n"
     ]
    }
   ],
   "source": [
    "print(observation_space)\n",
    "observation_space = spaces.Discrete(sum(ovec))\n",
    "print(observation_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11%4\n",
    "20//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['83763489212130077', '837634895065800895'], ['837634894702000876', '837634894751500878', '837634894566000874'], ['837634894919400880'], ['837634894923500881', '837634892436200172', '8376348953118001029', '837634894708900877', '837634894581900875', '837634894754900879', '837634892449700179', '83763489201030076', '837634895061000894', '837634892440900173']]\n"
     ]
    }
   ],
   "source": [
    "print(featureIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "onvec = []\n",
    "for i in range(len(featureIds)):\n",
    "    s = 0\n",
    "    for id in featureIds[i]:\n",
    "        s += len(get_tol_and_weight(tree=tree, id=id))\n",
    "        \n",
    "    onvec.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation_space():\n",
    "    observation_space = np.array([])\n",
    "    for i in range(len(featureIds)):\n",
    "        x = np.array([], dtype=np.float32)\n",
    "        for id in featureIds[i]:\n",
    "            x = np.append(x, utils.get_tol_and_weight(tree, id))\n",
    "        observation_space = np.append(observation_space, x)\n",
    "    return observation_space\n",
    "\n",
    "bounds = {\"H\": [1, 4], \"HBA\": [1, 5], \"HBD\": [1, 5], \"exclusion\": [0, 10], \"WGHT\": [0.1, 3]}\n",
    "\n",
    "def get_initial_os():\n",
    "    wght_low = bounds[\"WGHT\"][0]\n",
    "    wght_up = bounds[\"WGHT\"][1]\n",
    "    d = bounds.copy()\n",
    "    d.popitem()\n",
    "    for i in range(len(bounds.keys())-1):\n",
    "        feature = list(bounds.keys())[i]\n",
    "        lower = bounds[feature][0]\n",
    "        upper = bounds[feature][1]\n",
    "        up = []\n",
    "        down = []\n",
    "        if feature == \"exclusion\" or feature == \"H\":   \n",
    "            for _ in featureIds[i]:\n",
    "                up.extend([upper, wght_up])\n",
    "                down.extend([lower, wght_low])\n",
    "            d[feature] = spaces.Box(low=np.array(down), high=np.array(up), shape=(len(featureIds[i])*2,), dtype=np.float32)\n",
    "        if feature == \"HBA\" or feature == \"HBD\":\n",
    "            for _ in featureIds[i]:\n",
    "                up.extend([upper, upper, wght_up])\n",
    "                down.extend([lower, lower, wght_low])\n",
    "            d[feature] = spaces.Box(low=np.array(down), high=np.array(up), shape=(len(featureIds[i])*3,), dtype=np.float32)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "(20,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kilia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\spaces\\box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('H',\n",
       "              array([3.7234685, 1.5904604, 2.2449753, 2.0391967], dtype=float32)),\n",
       "             ('HBA',\n",
       "              array([3.6233723 , 4.7737703 , 2.0500684 , 1.4501897 , 3.2240496 ,\n",
       "                     0.62952703, 4.395515  , 2.034323  , 1.9348621 ], dtype=float32)),\n",
       "             ('HBD', array([3.553263 , 1.2815524, 2.5145724], dtype=float32)),\n",
       "             ('exclusion',\n",
       "              array([4.5976105 , 1.9447223 , 5.6468463 , 1.9731505 , 6.4719625 ,\n",
       "                     0.7851936 , 1.4741234 , 0.12440996, 8.091228  , 1.8296797 ,\n",
       "                     0.3141109 , 2.5040352 , 5.8465414 , 1.1841367 , 9.899724  ,\n",
       "                     1.3313555 , 5.2602425 , 0.18746142, 5.05088   , 2.798076  ],\n",
       "                    dtype=float32))])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os = spaces.Dict(get_initial_os())\n",
    "os.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation():\n",
    "        os_space = dict()\n",
    "        for i, f in zip(range(len(featureIds)),FEATURES):\n",
    "            x = []\n",
    "            for id in featureIds[i]:\n",
    "                x.extend(utils.get_tol_and_weight(tree, id))\n",
    "            os_space[f] = np.array(x, dtype=np.float32)\n",
    "        return os_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H': array([1.5, 1. , 1.5, 1. ], dtype=float32),\n",
       " 'HBA': array([1.5      , 1.9499999, 1.       , 1.5      , 1.9499999, 1.       ,\n",
       "        1.5      , 1.9499999, 1.       ], dtype=float32),\n",
       " 'HBD': array([1.9499999, 1.5      , 1.       ], dtype=float32),\n",
       " 'exclusion': array([1. , 1. , 1.5, 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1.5,\n",
       "        1. , 1.5, 1. , 1.5, 1. , 1.5, 1. ], dtype=float32)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_observation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "bounds = {\"H\": [1, 4], \"HBA\": [1, 5], \"HBD\": [1, 5]}\n",
    "last_observation = {'H': np.array([1.5, 1.7, 1.5, 1.1]),\n",
    "                    'HBA': np.array([1.5, 1.9499999, 1., 1.5, 1.9499999, 1., 1.5, 1.9499999, 1.]),\n",
    "                    'HBD': np.array([1.9499999, 2, 1.1])}\n",
    "terminated = False\n",
    "for key in last_observation.keys():\n",
    "            if terminated == True:\n",
    "                break\n",
    "            terminated = not(np.all(np.logical_and(last_observation[key] >= bounds[key][0], last_observation[key] <= bounds[key][1])))\n",
    "terminated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
