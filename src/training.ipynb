{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Environment and Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import PPO\n",
    "from customenv import PharmacophoreEnv\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "import wandb\n",
    "import time\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.registration import register\n",
    "from gymnasium.wrappers import FlattenObservation\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kilia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\spaces\\box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the env\n",
    "env = PharmacophoreEnv(output=r'C:\\Users\\kilia\\MASTER\\data\\hitlists\\hitlist', \n",
    "                       querys=r'C:\\Users\\kilia\\MASTER\\V2Z1551.pml', \n",
    "                       actives_db=r'C:\\Users\\kilia\\MASTER\\data\\seh_actives_mini.ldb', \n",
    "                       inactives_db=r\"C:\\Users\\kilia\\MASTER\\data\\seh_inactives_mini.ldb\",\n",
    "                       ldba=36,\n",
    "                       ldbi=112,\n",
    "                       features=\"H,HBA,HBD\")\n",
    "\n",
    "# check custom environment and output additional warnings if needed\n",
    "check_env(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kilia\\MASTER\\data\\venv\\lib\\site-packages\\gymnasium\\envs\\registration.py:693: UserWarning: \u001b[33mWARN: Overriding environment PharmacophoreEnv-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "# Example for the CartPole environment\n",
    "register(\n",
    "    # unique identifier for the env `name-version`\n",
    "    id=\"PharmacophoreEnv-v0\",\n",
    "    # path to the class for creating the env\n",
    "    entry_point=\"customenv:PharmacophoreEnv\",\n",
    "    # Max number of steps per episode, using a `TimeLimitWrapper`\n",
    "    kwargs={\"output\":r'C:\\Users\\kilia\\MASTER\\data\\hitlists\\hitlist', \n",
    "    \"querys\":r'C:\\Users\\kilia\\MASTER\\V2Z1551.pml', \n",
    "    \"actives_db\":r'C:\\Users\\kilia\\MASTER\\data\\seh_actives_mini.ldb', \n",
    "    \"inactives_db\":r\"C:\\Users\\kilia\\MASTER\\data\\seh_inactives_mini.ldb\",\n",
    "    \"ldba\":36,\n",
    "    \"ldbi\":112,\n",
    "    \"features\":\"H,HBA,HBD\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"PharmacophoreEnv-v0\")\n",
    "env = Monitor(env)\n",
    "# env = FlattenObservation(env)\n",
    "env.reset()\n",
    "batch_size = 64\n",
    "#env = make_vec_env(env_id=env, n_envs=6, vec_env_cls=SubprocVecEnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Creating environment from the given name 'PharmacophoreEnv-v0'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kilia\\MASTER\\data\\venv\\lib\\site-packages\\gymnasium\\envs\\registration.py:491: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'features']\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\kilia\\MASTER\\data\\venv\\lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found log directory outside of given root_logdir, dropping given root_logdir for event file in runs/PPO_1683009037\\PPO_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to runs/PPO_1683009037\\PPO_1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m#wandb.tensorboard.patch(root_logdir=f\"runs/{experiment_name}\")\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m#wandb.init(project=\"repharm\", config=config, name=experiment_name, sync_tensorboard=True)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# Define and Train the agent\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model \u001b[39m=\u001b[39m PPO(config[\u001b[39m\"\u001b[39m\u001b[39mpolicy_type\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mPharmacophoreEnv-v0\u001b[39m\u001b[39m\"\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, tensorboard_log\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mruns/\u001b[39m\u001b[39m{\u001b[39;00mexperiment_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, n_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m model\u001b[39m.\u001b[39;49mlearn(config[\u001b[39m\"\u001b[39;49m\u001b[39mtotal_timesteps\u001b[39;49m\u001b[39m\"\u001b[39;49m], \n\u001b[0;32m     10\u001b[0m         \u001b[39m#     callback=WandbCallback(gradient_save_freq=100,\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m         \u001b[39m#                            model_save_freq=1000, \u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m         \u001b[39m#                            model_save_path=f\"models/{experiment_name}\",\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m         \u001b[39m#                            verbose=2\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m         \u001b[39m# )\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m         )\n\u001b[0;32m     16\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mmodels/finals\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[39m#wandb.finish()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kilia\\MASTER\\data\\venv\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[39mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    309\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    310\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    311\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    312\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    313\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    314\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m    315\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kilia\\MASTER\\data\\venv\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:259\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 259\u001b[0m     continue_training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, callback, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrollout_buffer, n_rollout_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_steps)\n\u001b[0;32m    261\u001b[0m     \u001b[39mif\u001b[39;00m continue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kilia\\MASTER\\data\\venv\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:178\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space, spaces\u001b[39m.\u001b[39mBox):\n\u001b[0;32m    176\u001b[0m     clipped_actions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(actions, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mlow, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mhigh)\n\u001b[1;32m--> 178\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(clipped_actions)\n\u001b[0;32m    180\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[0;32m    182\u001b[0m \u001b[39m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kilia\\MASTER\\data\\venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:171\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[1;32mc:\\Users\\kilia\\MASTER\\data\\venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:57\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     55\u001b[0m     \u001b[39m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[1;32m---> 57\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[0;32m     58\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[0;32m     59\u001b[0m         )\n\u001b[0;32m     60\u001b[0m         \u001b[39m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     61\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx] \u001b[39m=\u001b[39m terminated \u001b[39mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\Users\\kilia\\MASTER\\data\\venv\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[0;32m     93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(\u001b[39mfloat\u001b[39m(reward))\n\u001b[0;32m     96\u001b[0m \u001b[39mif\u001b[39;00m terminated \u001b[39mor\u001b[39;00m truncated:\n",
      "File \u001b[1;32mc:\\Users\\kilia\\MASTER\\data\\venv\\lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\kilia\\MASTER\\data\\venv\\lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[0;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\kilia\\MASTER\\data\\customenv.py:72\u001b[0m, in \u001b[0;36mPharmacophoreEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mphar_modified \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39maction_execution(action, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatureIds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mphar)\n\u001b[0;32m     70\u001b[0m \u001b[39m# Evaluate and calculate reward\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m# self.render()\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscreen() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward\n\u001b[0;32m     73\u001b[0m terminated \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreshold:\n",
      "File \u001b[1;32mc:\\Users\\kilia\\MASTER\\data\\customenv.py:53\u001b[0m, in \u001b[0;36mPharmacophoreEnv.screen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemp_querys \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquerys[:\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_temp\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquerys[\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m:]\n\u001b[0;32m     52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mphar_modified\u001b[39m.\u001b[39mwrite(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemp_querys, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m, xml_declaration\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 53\u001b[0m actives, inactives \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mexec_vhts(output_file\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_file, \n\u001b[0;32m     54\u001b[0m                                      querys\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemp_querys, \n\u001b[0;32m     55\u001b[0m                                      actives_db\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactives_db, \n\u001b[0;32m     56\u001b[0m                                      inactives_db\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minactives_db)\n\u001b[0;32m     57\u001b[0m \u001b[39m# TODO: calculate score\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mif\u001b[39;00m actives \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kilia\\MASTER\\data\\utils.py:15\u001b[0m, in \u001b[0;36mexec_vhts\u001b[1;34m(output_file, querys, actives_db, inactives_db)\u001b[0m\n\u001b[0;32m     13\u001b[0m datestring \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mI_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS_\u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m output_file \u001b[39m=\u001b[39m output_file \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.sdf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(datestring)  \n\u001b[1;32m---> 15\u001b[0m subprocess\u001b[39m.\u001b[39;49mcall([\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mkilia\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mMASTER\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mscreen.bat\u001b[39;49m\u001b[39m'\u001b[39;49m, querys, output_file, actives_db, inactives_db], start_new_session\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     16\u001b[0m poshits \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     17\u001b[0m neghits \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:347\u001b[0m, in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m    346\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m         \u001b[39mreturn\u001b[39;00m p\u001b[39m.\u001b[39;49mwait(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    348\u001b[0m     \u001b[39mexcept\u001b[39;00m:  \u001b[39m# Including KeyboardInterrupt, wait handled that.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m         p\u001b[39m.\u001b[39mkill()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1207\u001b[0m     endtime \u001b[39m=\u001b[39m _time() \u001b[39m+\u001b[39m timeout\n\u001b[0;32m   1208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[39m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[39m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m     \u001b[39m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:1490\u001b[0m, in \u001b[0;36mPopen._wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     timeout_millis \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[0;32m   1488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1489\u001b[0m     \u001b[39m# API note: Returns immediately if timeout_millis == 0.\u001b[39;00m\n\u001b[1;32m-> 1490\u001b[0m     result \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mWaitForSingleObject(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle,\n\u001b[0;32m   1491\u001b[0m                                          timeout_millis)\n\u001b[0;32m   1492\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39m==\u001b[39m _winapi\u001b[39m.\u001b[39mWAIT_TIMEOUT:\n\u001b[0;32m   1493\u001b[0m         \u001b[39mraise\u001b[39;00m TimeoutExpired(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = {\"policy_type\": \"MultiInputPolicy\", \"total_timesteps\": 2500}\n",
    "experiment_name = f\"PPO_{int(time.time())}\"\n",
    "\n",
    "#wandb.tensorboard.patch(root_logdir=f\"runs/{experiment_name}\")\n",
    "#wandb.init(project=\"repharm\", config=config, name=experiment_name, sync_tensorboard=True)\n",
    "# Define and Train the agent\n",
    "model = PPO(config[\"policy_type\"], \"PharmacophoreEnv-v0\", verbose=2, tensorboard_log=f\"runs/{experiment_name}\", n_epochs=10)\n",
    "\n",
    "model.learn(config[\"total_timesteps\"], \n",
    "        #     callback=WandbCallback(gradient_save_freq=100,\n",
    "        #                            model_save_freq=1000, \n",
    "        #                            model_save_path=f\"models/{experiment_name}\",\n",
    "        #                            verbose=2\n",
    "        # )\n",
    "        )\n",
    "model.save(\"models/finals\")\n",
    "#wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found log directory outside of given root_logdir, dropping given root_logdir for event file in ./a2c_cartpole_tensorboard/A2C_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Creating environment from the given name 'CartPole-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./a2c_cartpole_tensorboard/A2C_2\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 32.2     |\n",
      "|    ep_rew_mean        | 32.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1534     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.684   |\n",
      "|    explained_variance | 0.0712   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 1.42     |\n",
      "|    value_loss         | 7.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 37.5     |\n",
      "|    ep_rew_mean        | 37.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1694     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.652   |\n",
      "|    explained_variance | 0.115    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.6      |\n",
      "|    value_loss         | 7.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 46.3     |\n",
      "|    ep_rew_mean        | 46.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1754     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.614   |\n",
      "|    explained_variance | -0.0201  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.78     |\n",
      "|    value_loss         | 6.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 53.1     |\n",
      "|    ep_rew_mean        | 53.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1766     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.614   |\n",
      "|    explained_variance | 0.0165   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 1.24     |\n",
      "|    value_loss         | 5.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 58.9     |\n",
      "|    ep_rew_mean        | 58.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1777     |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.584   |\n",
      "|    explained_variance | 0.0177   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.913    |\n",
      "|    value_loss         | 5.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 62.1     |\n",
      "|    ep_rew_mean        | 62.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1785     |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.614   |\n",
      "|    explained_variance | 0.00364  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.839    |\n",
      "|    value_loss         | 4.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 65.2     |\n",
      "|    ep_rew_mean        | 65.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1795     |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.576   |\n",
      "|    explained_variance | 0.00532  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.781    |\n",
      "|    value_loss         | 3.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 70.3     |\n",
      "|    ep_rew_mean        | 70.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1795     |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.469   |\n",
      "|    explained_variance | 0.00138  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.331    |\n",
      "|    value_loss         | 3.36     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 76.1      |\n",
      "|    ep_rew_mean        | 76.1      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1801      |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.566    |\n",
      "|    explained_variance | -0.000396 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 0.525     |\n",
      "|    value_loss         | 2.87      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 82.3     |\n",
      "|    ep_rew_mean        | 82.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1805     |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.364   |\n",
      "|    explained_variance | 0.00106  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 1.18     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 86.6      |\n",
      "|    ep_rew_mean        | 86.6      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1803      |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.459    |\n",
      "|    explained_variance | -5.87e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 0.673     |\n",
      "|    value_loss         | 1.98      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 90        |\n",
      "|    ep_rew_mean        | 90        |\n",
      "| time/                 |           |\n",
      "|    fps                | 1804      |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.375    |\n",
      "|    explained_variance | -3.89e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 0.791     |\n",
      "|    value_loss         | 1.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 96.4      |\n",
      "|    ep_rew_mean        | 96.4      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1807      |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.432    |\n",
      "|    explained_variance | -7.77e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 0.567     |\n",
      "|    value_loss         | 1.24      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 103       |\n",
      "|    ep_rew_mean        | 103       |\n",
      "| time/                 |           |\n",
      "|    fps                | 1812      |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.475    |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 0.484     |\n",
      "|    value_loss         | 0.934     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | 109      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1812     |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.46    |\n",
      "|    explained_variance | -0.0001  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.35     |\n",
      "|    value_loss         | 0.669    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 116      |\n",
      "|    ep_rew_mean        | 116      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1814     |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.376   |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.158    |\n",
      "|    value_loss         | 0.462    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 116       |\n",
      "|    ep_rew_mean        | 116       |\n",
      "| time/                 |           |\n",
      "|    fps                | 1815      |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.266    |\n",
      "|    explained_variance | -0.000188 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 0.204     |\n",
      "|    value_loss         | 0.294     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 117      |\n",
      "|    ep_rew_mean        | 117      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1818     |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.386   |\n",
      "|    explained_variance | 5.07e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.141    |\n",
      "|    value_loss         | 0.162    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 119       |\n",
      "|    ep_rew_mean        | 119       |\n",
      "| time/                 |           |\n",
      "|    fps                | 1818      |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.377    |\n",
      "|    explained_variance | -3.93e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 0.0614    |\n",
      "|    value_loss         | 0.0685    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 121      |\n",
      "|    ep_rew_mean        | 121      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1820     |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.294   |\n",
      "|    explained_variance | -8.3e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.012    |\n",
      "|    value_loss         | 0.015    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x211ed868310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "\n",
    "model = A2C(\"MlpPolicy\", \"CartPole-v1\", verbose=2, tensorboard_log=\"./a2c_cartpole_tensorboard/\")\n",
    "model.learn(total_timesteps=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
